{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T07:21:28.499694Z",
     "start_time": "2024-04-03T07:21:28.486565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([8, 256, 64]), torch.Size([256, 8, 8]))"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "inputs = torch.randn(8, 256, 64)\n",
    "att = torch.nn.MultiheadAttention(64, 2, 0.1)\n",
    "outputs, weights = att(inputs, inputs, inputs)\n",
    "outputs.shape, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1, 256, 64]), torch.Size([256, 1, 1]))"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 假设的嵌入向量\n",
    "text_embedding = torch.randn(256, 64)  # (batch_size, embed_size)\n",
    "video_embedding = torch.randn(256, 64)  # (batch_size, embed_size)\n",
    "\n",
    "# 调整嵌入向量以匹配 MultiheadAttention 输入\n",
    "text_embedding = text_embedding.unsqueeze(0)  # (1, batch_size, embed_size)\n",
    "video_embedding = video_embedding.unsqueeze(0)  # (1, batch_size, embed_size)\n",
    "\n",
    "# 使用 MultiheadAttention\n",
    "att = torch.nn.MultiheadAttention(64, 4, 0.1)\n",
    "output, weights = att(text_embedding, video_embedding, video_embedding)\n",
    "output.shape, weights.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T07:18:30.695255Z",
     "start_time": "2024-04-03T07:18:30.688105Z"
    }
   },
   "id": "8e5e723fbb2d487a",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([30, 1, 64]), torch.Size([1, 30, 30]))"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设文本和图像特征已经准备好，且它们的嵌入维度相同\n",
    "text_features = torch.randn(10, 1, 64)  # 文本特征形状: (seq_len, batch, embed_dim)\n",
    "image_features = torch.randn(20, 1, 64)  # 图像特征形状: (seq_len, batch, embed_dim)\n",
    "\n",
    "# 将文本和图像特征沿着序列维度拼接\n",
    "combined_features = torch.cat([text_features, image_features], dim=0)  # (seq_len_text + seq_len_image, batch, embed_dim)\n",
    "\n",
    "# 初始化多头注意力机制\n",
    "multihead_attn = nn.MultiheadAttention(embed_dim=64, num_heads=4)\n",
    "\n",
    "# 应用多头注意力机制来学习模态间的交互\n",
    "# 注意：在实际使用中，可能需要额外的mask或者padding操作来处理不同长度的序列\n",
    "output, attn_weights = multihead_attn(combined_features, combined_features, combined_features)\n",
    "output.shape, attn_weights.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T07:35:19.681030Z",
     "start_time": "2024-04-03T07:35:19.674592Z"
    }
   },
   "id": "17c3ca3a23e20ab8",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "53cf4eb8d1a7e853"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256, 64]) torch.Size([256, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设文本和图像特征的形状都是(8, 256, 64)，意味着有8个序列（这里可以理解为8个不同的数据样本或者时间步），每个序列有256个元素，每个元素是一个64维的特征向量\n",
    "text_features = torch.randn(8, 256, 64)\n",
    "image_features = torch.randn(8, 256, 64)\n",
    "\n",
    "# 初始化多头注意力机制\n",
    "multihead_attn = nn.MultiheadAttention(64, 2, dropout=0.1)\n",
    "\n",
    "# 使用文本作为查询（Query），图像作为键（Key）和值（Value）\n",
    "outputs, weights = multihead_attn(query=text_features, key=image_features, value=image_features)\n",
    "\n",
    "print(outputs.shape, weights.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T08:29:25.010024Z",
     "start_time": "2024-04-03T08:29:25.001237Z"
    }
   },
   "id": "24492091ad725ca7",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设文本和图像特征的形状都是(8, 256, 64)，意味着有8个序列（这里可以理解为8个不同的数据样本或者时间步），每个序列有256个元素，每个元素是一个64维的特征向量\n",
    "text_features = torch.randn(8, 256, 64)\n",
    "image_features = torch.randn(8, 256, 64)\n",
    "# 初始化多头注意力机制\n",
    "multihead_attn = torch.nn.MultiheadAttention(embed_dim=64, num_heads=2, dropout=0.1)\n",
    "\n",
    "# 文本注意图像（文本作为查询，图像作为键和值）\n",
    "text_query_image, _ = multihead_attn(query=text_features, key=image_features, value=image_features)\n",
    "\n",
    "# 或者图像注意文本（图像作为查询，文本作为键和值）\n",
    "image_query_text, _ = multihead_attn(query=image_features, key=text_features, value=text_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T09:29:23.975497Z",
     "start_time": "2024-04-03T09:29:23.956455Z"
    }
   },
   "id": "a62f29385b747009",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 64]) torch.Size([8, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设的批次大小和特征维度\n",
    "batch_size = 8\n",
    "dim = 64\n",
    "\n",
    "# 生成文本和图像特征\n",
    "text_features = torch.randn(batch_size, dim)\n",
    "image_features = torch.randn(batch_size, dim)\n",
    "\n",
    "# 为了匹配MultiheadAttention的输入形状，我们需要增加一个维度来表示序列长度\n",
    "# 新的形状将会是 (1, batch_size, dim)\n",
    "text_features = text_features.unsqueeze(0)  # 增加序列长度维度\n",
    "image_features = image_features.unsqueeze(0)  # 增加序列长度维度\n",
    "\n",
    "# 初始化多头注意力机制\n",
    "multihead_attn = torch.nn.MultiheadAttention(embed_dim=dim, num_heads=2, dropout=0.1)\n",
    "\n",
    "# 实现交叉注意力机制\n",
    "# 这里以文本特征为查询（Q），图像特征为键（K）和值（V）\n",
    "outputs, weights = multihead_attn(query=text_features, key=image_features, value=image_features)\n",
    "\n",
    "print(outputs.shape, weights.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T09:31:51.225459Z",
     "start_time": "2024-04-03T09:31:51.219764Z"
    }
   },
   "id": "8f87711f96c5c091",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6733ab04f2650fe3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
